{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for similarity need to download larger english word library with the below in gitbash \n",
    "# python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import pyspark\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('pandasToSparkDF').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv(\"movie20.csv\")\n",
    "file_all = pd.read_csv(\"final_moviedata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.DataFrame(file)\n",
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_all = pd.DataFrame(file_all)\n",
    "file_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_all.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.drop_duplicates(keep='first', inplace=True)\n",
    "file_all.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_df2 = file[[\"imdb_id\",\"title\", \"overview\"]].copy()\n",
    "overview_df2.dropna(inplace=True)\n",
    "overview_df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = file_all[[\"imdb_id\",\"title\", \"overview\"]].copy()\n",
    "df_all.dropna(inplace=True)\n",
    "df_all.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_df2.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceData = spark.createDataFrame(overview_df2.astype(str))\n",
    "sentenceData.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceData_all = spark.createDataFrame(df_all.astype(str))\n",
    "sentenceData_all.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"overview\", outputCol=\"words\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform and show DataFrame\n",
    "tokenized = tokenizer.transform(sentenceData)\n",
    "tokenized_all = tokenizer.transform(sentenceData_all)\n",
    "tokenized.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Remover\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"nostopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform and show data\n",
    "tokenized = remover.transform(tokenized)\n",
    "tokenized_all = remover.transform(tokenized_all)\n",
    "tokenized.show(truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_all.show(truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Spacy Similarity code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "#MAKE SURE THIS IS LARGE LIBRARY\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding columns for similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to compare each movie to the all movie and recommend top 3\n",
    "ll = []\n",
    "result = []\n",
    "for m in tokenized.collect():\n",
    "    main_row = str(m.nostopwords)\n",
    "    docA = nlp(main_row)\n",
    "    for f in tokenized_all.collect():\n",
    "\n",
    "        overview_row = str(f.nostopwords)\n",
    "        #print(overview_row)\n",
    "        doc_row = nlp(overview_row)\n",
    "\n",
    "        compare = docA.similarity(doc_row)\n",
    "        ll.append({'imdb_id': f.imdb_id,'Title': f.title,\n",
    "                   'Similarity': compare })\n",
    "# sample = tokenized.withColumn('similarity', lit(str(ll)))\n",
    "# ll   \n",
    "    df_simi = pd.DataFrame(ll)\n",
    "    df_simi.sort_values(by=['Similarity'], inplace=True, ascending=False)\n",
    "    df_simi.reset_index(drop=True)\n",
    "    top3_df = df_simi.iloc[1:4]\n",
    "    result.append({'imdb_id': m.imdb_id,'Title': m.title, 'Recom1': top3_df.iloc[0,2],\n",
    "                  'Recom2': top3_df.iloc[1,2], 'Recom3': top3_df.iloc[2,2]})\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing recommandation to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recomm = pd.DataFrame(result)\n",
    "df_recomm.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this code for the first time to create the csv file\n",
    "df_recomm.to_csv('/Users/ericH/Desktop/moviesDashboard/raw/recom.csv', index = None, header=True)\n",
    "df_recomm.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this code to add to csv file\n",
    "# df_recomm.to_csv('/Users/ericH/Desktop/moviesDashboard/raw/recom.csv', mode='a', index = None, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/ericH/Desktop/moviesDashboard/raw/recom.csv'\n",
    "with open(file_path, mode='a', newline='\\n') as f:\n",
    "            df_recomm.to_csv(f, index = None, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
